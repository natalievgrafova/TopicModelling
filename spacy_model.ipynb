{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-10 16:53:00.959506: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "#Imports \n",
    "import pandas as pd\n",
    "import spacy\n",
    "from spacy.lang.fr import French\n",
    "from spacy.tokens import Doc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.corpora.dictionary import Dictionary\n",
    "from gensim.models import LdaMulticore\n",
    "from gensim.models import CoherenceModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fr_core_news_lg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('fr_core_news_lg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_articles = pd.read_csv('clean_french_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "key_words_data = ['données personnelles','base des données', 'confidentialité','partager des données', 'accès aux données', 'réutilisation des données', 'utilisation des données', 'analyse des données', 'usage des données', 'protection des données']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = all_articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "45158"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[['title', 'text', 'date', 'url', '_id']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_data = []\n",
    "for row in range(len(df)):\n",
    "    if any(word in str(df.iloc[row, 1]) for word in key_words_data):\n",
    "        if str(df.iloc[row, 1]) not in list_data:\n",
    "            list_data.append(str(df.iloc[row, 1]))\n",
    "\n",
    "df = df[df['text'].isin(list_data)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5434"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df['text'].isin(list_data)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5434"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "first argument must be string or compiled pattern",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m df \u001b[39m=\u001b[39m df[df\u001b[39m.\u001b[39;49mtext\u001b[39m.\u001b[39;49mstr\u001b[39m.\u001b[39;49mcontains(text \u001b[39min\u001b[39;49;00m list_data \u001b[39mfor\u001b[39;49;00m text \u001b[39min\u001b[39;49;00m list_data)]\n",
      "File \u001b[0;32m~/Documents/GitHub/TopicModelling/nlp_env/lib/python3.11/site-packages/pandas/core/strings/accessor.py:129\u001b[0m, in \u001b[0;36mforbid_nonstring_types.<locals>._forbid_nonstring_types.<locals>.wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    124\u001b[0m     msg \u001b[39m=\u001b[39m (\n\u001b[1;32m    125\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mCannot use .str.\u001b[39m\u001b[39m{\u001b[39;00mfunc_name\u001b[39m}\u001b[39;00m\u001b[39m with values of \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    126\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39minferred dtype \u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_inferred_dtype\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    127\u001b[0m     )\n\u001b[1;32m    128\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(msg)\n\u001b[0;32m--> 129\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39mself\u001b[39;49m, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/Documents/GitHub/TopicModelling/nlp_env/lib/python3.11/site-packages/pandas/core/strings/accessor.py:1281\u001b[0m, in \u001b[0;36mStringMethods.contains\u001b[0;34m(self, pat, case, flags, na, regex)\u001b[0m\n\u001b[1;32m   1154\u001b[0m \u001b[39m@forbid_nonstring_types\u001b[39m([\u001b[39m\"\u001b[39m\u001b[39mbytes\u001b[39m\u001b[39m\"\u001b[39m])\n\u001b[1;32m   1155\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcontains\u001b[39m(\n\u001b[1;32m   1156\u001b[0m     \u001b[39mself\u001b[39m, pat, case: \u001b[39mbool\u001b[39m \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m, flags: \u001b[39mint\u001b[39m \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m, na\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, regex: \u001b[39mbool\u001b[39m \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m   1157\u001b[0m ):\n\u001b[1;32m   1158\u001b[0m \u001b[39m    \u001b[39m\u001b[39mr\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   1159\u001b[0m \u001b[39m    Test if pattern or regex is contained within a string of a Series or Index.\u001b[39;00m\n\u001b[1;32m   1160\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1279\u001b[0m \u001b[39m    dtype: bool\u001b[39;00m\n\u001b[1;32m   1280\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1281\u001b[0m     \u001b[39mif\u001b[39;00m regex \u001b[39mand\u001b[39;00m re\u001b[39m.\u001b[39;49mcompile(pat)\u001b[39m.\u001b[39mgroups:\n\u001b[1;32m   1282\u001b[0m         warnings\u001b[39m.\u001b[39mwarn(\n\u001b[1;32m   1283\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mThis pattern is interpreted as a regular expression, and has \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1284\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mmatch groups. To actually get the groups, use str.extract.\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m   1285\u001b[0m             \u001b[39mUserWarning\u001b[39;00m,\n\u001b[1;32m   1286\u001b[0m             stacklevel\u001b[39m=\u001b[39mfind_stack_level(),\n\u001b[1;32m   1287\u001b[0m         )\n\u001b[1;32m   1289\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_data\u001b[39m.\u001b[39marray\u001b[39m.\u001b[39m_str_contains(pat, case, flags, na, regex)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/re/__init__.py:227\u001b[0m, in \u001b[0;36mcompile\u001b[0;34m(pattern, flags)\u001b[0m\n\u001b[1;32m    225\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcompile\u001b[39m(pattern, flags\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m):\n\u001b[1;32m    226\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mCompile a regular expression pattern, returning a Pattern object.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m--> 227\u001b[0m     \u001b[39mreturn\u001b[39;00m _compile(pattern, flags)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/re/__init__.py:286\u001b[0m, in \u001b[0;36m_compile\u001b[0;34m(pattern, flags)\u001b[0m\n\u001b[1;32m    284\u001b[0m     \u001b[39mreturn\u001b[39;00m pattern\n\u001b[1;32m    285\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m _compiler\u001b[39m.\u001b[39misstring(pattern):\n\u001b[0;32m--> 286\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mfirst argument must be string or compiled pattern\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    287\u001b[0m \u001b[39mif\u001b[39;00m flags \u001b[39m&\u001b[39m T:\n\u001b[1;32m    288\u001b[0m     \u001b[39mimport\u001b[39;00m \u001b[39mwarnings\u001b[39;00m\n",
      "\u001b[0;31mTypeError\u001b[0m: first argument must be string or compiled pattern"
     ]
    }
   ],
   "source": [
    "df = df[df.text.str.contains(text in list_data for text in list_data)]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unhashable type: 'list'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m df \u001b[39m=\u001b[39m df[df\u001b[39m.\u001b[39;49mtext\u001b[39m.\u001b[39;49mstr\u001b[39m.\u001b[39;49mcontains(key_words_data)]\n",
      "File \u001b[0;32m~/Documents/GitHub/TopicModelling/nlp_env/lib/python3.11/site-packages/pandas/core/strings/accessor.py:129\u001b[0m, in \u001b[0;36mforbid_nonstring_types.<locals>._forbid_nonstring_types.<locals>.wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    124\u001b[0m     msg \u001b[39m=\u001b[39m (\n\u001b[1;32m    125\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mCannot use .str.\u001b[39m\u001b[39m{\u001b[39;00mfunc_name\u001b[39m}\u001b[39;00m\u001b[39m with values of \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    126\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39minferred dtype \u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_inferred_dtype\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    127\u001b[0m     )\n\u001b[1;32m    128\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(msg)\n\u001b[0;32m--> 129\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39mself\u001b[39;49m, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/Documents/GitHub/TopicModelling/nlp_env/lib/python3.11/site-packages/pandas/core/strings/accessor.py:1281\u001b[0m, in \u001b[0;36mStringMethods.contains\u001b[0;34m(self, pat, case, flags, na, regex)\u001b[0m\n\u001b[1;32m   1154\u001b[0m \u001b[39m@forbid_nonstring_types\u001b[39m([\u001b[39m\"\u001b[39m\u001b[39mbytes\u001b[39m\u001b[39m\"\u001b[39m])\n\u001b[1;32m   1155\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcontains\u001b[39m(\n\u001b[1;32m   1156\u001b[0m     \u001b[39mself\u001b[39m, pat, case: \u001b[39mbool\u001b[39m \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m, flags: \u001b[39mint\u001b[39m \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m, na\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, regex: \u001b[39mbool\u001b[39m \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m   1157\u001b[0m ):\n\u001b[1;32m   1158\u001b[0m \u001b[39m    \u001b[39m\u001b[39mr\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   1159\u001b[0m \u001b[39m    Test if pattern or regex is contained within a string of a Series or Index.\u001b[39;00m\n\u001b[1;32m   1160\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1279\u001b[0m \u001b[39m    dtype: bool\u001b[39;00m\n\u001b[1;32m   1280\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1281\u001b[0m     \u001b[39mif\u001b[39;00m regex \u001b[39mand\u001b[39;00m re\u001b[39m.\u001b[39;49mcompile(pat)\u001b[39m.\u001b[39mgroups:\n\u001b[1;32m   1282\u001b[0m         warnings\u001b[39m.\u001b[39mwarn(\n\u001b[1;32m   1283\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mThis pattern is interpreted as a regular expression, and has \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1284\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mmatch groups. To actually get the groups, use str.extract.\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m   1285\u001b[0m             \u001b[39mUserWarning\u001b[39;00m,\n\u001b[1;32m   1286\u001b[0m             stacklevel\u001b[39m=\u001b[39mfind_stack_level(),\n\u001b[1;32m   1287\u001b[0m         )\n\u001b[1;32m   1289\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_data\u001b[39m.\u001b[39marray\u001b[39m.\u001b[39m_str_contains(pat, case, flags, na, regex)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/re/__init__.py:227\u001b[0m, in \u001b[0;36mcompile\u001b[0;34m(pattern, flags)\u001b[0m\n\u001b[1;32m    225\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcompile\u001b[39m(pattern, flags\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m):\n\u001b[1;32m    226\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mCompile a regular expression pattern, returning a Pattern object.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m--> 227\u001b[0m     \u001b[39mreturn\u001b[39;00m _compile(pattern, flags)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/re/__init__.py:277\u001b[0m, in \u001b[0;36m_compile\u001b[0;34m(pattern, flags)\u001b[0m\n\u001b[1;32m    275\u001b[0m     flags \u001b[39m=\u001b[39m flags\u001b[39m.\u001b[39mvalue\n\u001b[1;32m    276\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 277\u001b[0m     \u001b[39mreturn\u001b[39;00m _cache[\u001b[39mtype\u001b[39;49m(pattern), pattern, flags]\n\u001b[1;32m    278\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m:\n\u001b[1;32m    279\u001b[0m     \u001b[39mpass\u001b[39;00m\n",
      "\u001b[0;31mTypeError\u001b[0m: unhashable type: 'list'"
     ]
    }
   ],
   "source": [
    "df = df[df.text.str.contains(key_words_data)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>_id</th>\n",
       "      <th>url</th>\n",
       "      <th>date</th>\n",
       "      <th>text</th>\n",
       "      <th>title</th>\n",
       "      <th>langs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>5ec760320e5c92500d004aee</td>\n",
       "      <td>https://plus.lesoir.be/302282/article/2020-05-...</td>\n",
       "      <td>2020-05-22T04:22:52.000Z</td>\n",
       "      <td>Les concentrations de différents polluants rel...</td>\n",
       "      <td>La qualité de l’air en nette amélioration à Br...</td>\n",
       "      <td>fr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>5ec7603216193c3860cf1616</td>\n",
       "      <td>https://www.rtbf.be/info/regions/detail_corona...</td>\n",
       "      <td>2020-05-22T04:37:03.000Z</td>\n",
       "      <td>L’amélioration de la qualité de l’air bruxello...</td>\n",
       "      <td>Coronavirus à Bruxelles : on respire mieux grâ...</td>\n",
       "      <td>fr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>5ec76032039b233f9642aeb6</td>\n",
       "      <td>https://plus.lesoir.be/302121/article/2020-05-...</td>\n",
       "      <td>2020-05-20T19:36:26.000Z</td>\n",
       "      <td>La résolution pose plusieurs principes tel que...</td>\n",
       "      <td>La Chambre vote une résolution encadrant l’usa...</td>\n",
       "      <td>fr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>5ec760320e5c92500d004af3</td>\n",
       "      <td>https://plus.lesoir.be/302273/article/2020-05-...</td>\n",
       "      <td>2020-05-21T21:01:32.000Z</td>\n",
       "      <td>Le nouveau coronavirus a officiellement touché...</td>\n",
       "      <td>Plus de cinq millions de cas de Covid-19 dans ...</td>\n",
       "      <td>fr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>5ec7603216193c3860cf161f</td>\n",
       "      <td>https://www.rtbf.be/info/economie/detail_coron...</td>\n",
       "      <td>2020-05-22T04:00:00.000Z</td>\n",
       "      <td>Les résultats d’une enquête menée par le prest...</td>\n",
       "      <td>Coronavirus en Belgique : les ouvriers plus to...</td>\n",
       "      <td>fr</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                       _id  \\\n",
       "0           0  5ec760320e5c92500d004aee   \n",
       "1           1  5ec7603216193c3860cf1616   \n",
       "2           2  5ec76032039b233f9642aeb6   \n",
       "3           3  5ec760320e5c92500d004af3   \n",
       "4           4  5ec7603216193c3860cf161f   \n",
       "\n",
       "                                                 url  \\\n",
       "0  https://plus.lesoir.be/302282/article/2020-05-...   \n",
       "1  https://www.rtbf.be/info/regions/detail_corona...   \n",
       "2  https://plus.lesoir.be/302121/article/2020-05-...   \n",
       "3  https://plus.lesoir.be/302273/article/2020-05-...   \n",
       "4  https://www.rtbf.be/info/economie/detail_coron...   \n",
       "\n",
       "                       date  \\\n",
       "0  2020-05-22T04:22:52.000Z   \n",
       "1  2020-05-22T04:37:03.000Z   \n",
       "2  2020-05-20T19:36:26.000Z   \n",
       "3  2020-05-21T21:01:32.000Z   \n",
       "4  2020-05-22T04:00:00.000Z   \n",
       "\n",
       "                                                text  \\\n",
       "0  Les concentrations de différents polluants rel...   \n",
       "1  L’amélioration de la qualité de l’air bruxello...   \n",
       "2  La résolution pose plusieurs principes tel que...   \n",
       "3  Le nouveau coronavirus a officiellement touché...   \n",
       "4  Les résultats d’une enquête menée par le prest...   \n",
       "\n",
       "                                               title langs  \n",
       "0  La qualité de l’air en nette amélioration à Br...    fr  \n",
       "1  Coronavirus à Bruxelles : on respire mieux grâ...    fr  \n",
       "2  La Chambre vote une résolution encadrant l’usa...    fr  \n",
       "3  Plus de cinq millions de cas de Covid-19 dans ...    fr  \n",
       "4  Coronavirus en Belgique : les ouvriers plus to...    fr  "
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_articles.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "articles_all = all_articles[['title', 'text', 'date', 'url', '_id']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>date</th>\n",
       "      <th>url</th>\n",
       "      <th>_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>La qualité de l’air en nette amélioration à Br...</td>\n",
       "      <td>Les concentrations de différents polluants rel...</td>\n",
       "      <td>2020-05-22T04:22:52.000Z</td>\n",
       "      <td>https://plus.lesoir.be/302282/article/2020-05-...</td>\n",
       "      <td>5ec760320e5c92500d004aee</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Coronavirus à Bruxelles : on respire mieux grâ...</td>\n",
       "      <td>L’amélioration de la qualité de l’air bruxello...</td>\n",
       "      <td>2020-05-22T04:37:03.000Z</td>\n",
       "      <td>https://www.rtbf.be/info/regions/detail_corona...</td>\n",
       "      <td>5ec7603216193c3860cf1616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>La Chambre vote une résolution encadrant l’usa...</td>\n",
       "      <td>La résolution pose plusieurs principes tel que...</td>\n",
       "      <td>2020-05-20T19:36:26.000Z</td>\n",
       "      <td>https://plus.lesoir.be/302121/article/2020-05-...</td>\n",
       "      <td>5ec76032039b233f9642aeb6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Plus de cinq millions de cas de Covid-19 dans ...</td>\n",
       "      <td>Le nouveau coronavirus a officiellement touché...</td>\n",
       "      <td>2020-05-21T21:01:32.000Z</td>\n",
       "      <td>https://plus.lesoir.be/302273/article/2020-05-...</td>\n",
       "      <td>5ec760320e5c92500d004af3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Coronavirus en Belgique : les ouvriers plus to...</td>\n",
       "      <td>Les résultats d’une enquête menée par le prest...</td>\n",
       "      <td>2020-05-22T04:00:00.000Z</td>\n",
       "      <td>https://www.rtbf.be/info/economie/detail_coron...</td>\n",
       "      <td>5ec7603216193c3860cf161f</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0  La qualité de l’air en nette amélioration à Br...   \n",
       "1  Coronavirus à Bruxelles : on respire mieux grâ...   \n",
       "2  La Chambre vote une résolution encadrant l’usa...   \n",
       "3  Plus de cinq millions de cas de Covid-19 dans ...   \n",
       "4  Coronavirus en Belgique : les ouvriers plus to...   \n",
       "\n",
       "                                                text  \\\n",
       "0  Les concentrations de différents polluants rel...   \n",
       "1  L’amélioration de la qualité de l’air bruxello...   \n",
       "2  La résolution pose plusieurs principes tel que...   \n",
       "3  Le nouveau coronavirus a officiellement touché...   \n",
       "4  Les résultats d’une enquête menée par le prest...   \n",
       "\n",
       "                       date  \\\n",
       "0  2020-05-22T04:22:52.000Z   \n",
       "1  2020-05-22T04:37:03.000Z   \n",
       "2  2020-05-20T19:36:26.000Z   \n",
       "3  2020-05-21T21:01:32.000Z   \n",
       "4  2020-05-22T04:00:00.000Z   \n",
       "\n",
       "                                                 url                       _id  \n",
       "0  https://plus.lesoir.be/302282/article/2020-05-...  5ec760320e5c92500d004aee  \n",
       "1  https://www.rtbf.be/info/regions/detail_corona...  5ec7603216193c3860cf1616  \n",
       "2  https://plus.lesoir.be/302121/article/2020-05-...  5ec76032039b233f9642aeb6  \n",
       "3  https://plus.lesoir.be/302273/article/2020-05-...  5ec760320e5c92500d004af3  \n",
       "4  https://www.rtbf.be/info/economie/detail_coron...  5ec7603216193c3860cf161f  "
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "articles_all.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "articles_1000 = articles_all[:999]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "key_words = ['technologie','technologies', 'technologique', 'politique', 'gouvernement', 'sécurité', 'données personnelles', 'confidentialité','partager', 'accès aux données', 'réutilisation des données','utilisation des données', 'sport', 'musique', 'économie', 'société', 'clinique', 'médicament', 'hôpital', 'enfant', 'études' ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_data = []\n",
    "for row in range(len(articles_all)):\n",
    "    if any(word in str(articles_all.iloc[row, 1]) for word in key_words_data):\n",
    "        if str(articles_all.iloc[row, 1]) not in list_data:\n",
    "            list_data.append(str(articles_all.iloc[row, 1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m test_df \u001b[39m=\u001b[39m df\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "test_df = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [],
   "source": [
    "key_words_data = ['données personnelles','base des données', 'confidentialité','partager', 'accès aux données', 'réutilisation des données', 'utilisation des données', 'analyse des données', 'usage des données', 'protection des données']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_test = []\n",
    "for row in range(len(articles_all)): \n",
    "    if 'protection des données' in str(articles_all.iloc[row, 1]):\n",
    "        list_test.append(articles_all.iloc[row, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6193"
      ]
     },
     "execution_count": 254,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_10000 = list_chosen[:10000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Le secteur de la santé a d’urgence besoin de personnel supplémentaire pour garantir le maintien des soins pendant la pandémie. C’est pourquoi la ministre flamande de l’Emploi Hilde Crevits (CD&V) a mis en place la plateforme helpindezorg.be. Les institutions de soins peuvent y détailler leurs besoins et les candidats s’y signaler.\\\\n\\\\nComme d’autres, le secteur de la santé est confronté à des absences liées aux quarantaines et maladies et a donc besoin de soutien. Les chômeurs temporaires, indépendants et jobistes qui sont pour l’instant inoccupés (comme par exemple ceux travaillant dans l’horeca ou l’événementiel) peuvent l’aider, estime le gouvernement flamand. Il s’agirait notamment de livrer des repas, d’accueillir et orienter les visiteurs, de désinfecter le matériel, de travailler au centre d’appels, etc.\\\\n\\\\nPour faciliter la rencontre entre les besoins et les offres, l’office de l’emploi VDAB a mis sur pied helpindezorg.be. Les collaborateurs du VDAB chercheront également directement les profils adéquats et détiennent, pour la première fois, les données relatives aux chômeurs temporaires afin de pouvoir également les contacter.\\\\n\\\\nLes candidatures se font cependant sur base volontaire. « Il s’agit d’emplois temporaires bien définis dans le secteur des soins. Quand l’employeur originel redémarrera son activité, l’employé pourra rapidement y retourner. » Le gouvernement flamand demande d’ailleurs au ministre fédéral Pierre-Yves Dermagne de clarifier la possibilité d’être employé ailleurs pendant le chômage temporaire.\\\\n\\\\nCes emplois seront payés selon les barèmes en vigueur dans le secteur des soins et les indépendants pourront facturer leurs services.'"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_10000[5559]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'En 2013, Google créait une nouvelle filiale, Calico. Son but, un brin ambitieux : « tuer la mort ». Dit autrement, lutter contre le vieillissement en ressuscitant le vieux fantasme de transhumanisme consistant à « augmenter » l’humain grâce à la technologie. Calico ne donne aujourd’hui plus signe de vie. Mais entre-temps, Google a conclu un accord controversé avec 150 hôpitaux aux Etats-Unis lui offrant un accès aux données médicales de millions de patients. En 2014, elle rachetait Deepmind pour 628 millions de dollars. La branche « Intelligence artificielle » de Google utilise les données sur les génomes pour prédire la structure des protéines des organismes, ce qui pourrait permettre de dégager une réponse thérapeutique au Covid-19.'"
      ]
     },
     "execution_count": 257,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_data[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6193"
      ]
     },
     "execution_count": 294,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_tagged= ['VERB','ADV','PRON','CCONJ','PUNCT','PART','DET','ADP','SPACE', 'NUM', 'SYM']\n",
    "#add verbs?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens_1000 = []\n",
    "for text in nlp.pipe(articles_1000['text']):\n",
    "   proj_tok = [token.lemma_.lower() for token in text if token.pos_ not in remove_tagged and not token.is_stop and token.is_alpha]\n",
    "   tokens_1000.append(proj_tok)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens_data = []\n",
    "for text in nlp.pipe(list_data):\n",
    "   proj_tok = [token.lemma_.lower() for token in text if token.pos_ not in remove_tagged and not token.is_stop and token.is_alpha]\n",
    "   tokens_data.append(proj_tok)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['google',\n",
       " 'nouveau',\n",
       " 'filiale',\n",
       " 'calico',\n",
       " 'but',\n",
       " 'brin',\n",
       " 'ambitieux',\n",
       " 'mort',\n",
       " 'vieillissement',\n",
       " 'vieux',\n",
       " 'fantasme',\n",
       " 'transhumanisme',\n",
       " 'humain',\n",
       " 'grâce',\n",
       " 'technologie',\n",
       " 'calico',\n",
       " 'signe',\n",
       " 'vie',\n",
       " 'google',\n",
       " 'accord',\n",
       " 'hôpital',\n",
       " 'accès',\n",
       " 'donnée',\n",
       " 'médical',\n",
       " 'million',\n",
       " 'patient',\n",
       " 'deepmind',\n",
       " 'million',\n",
       " 'dollar',\n",
       " 'branche',\n",
       " 'intelligence',\n",
       " 'artificiel',\n",
       " 'google',\n",
       " 'donnée',\n",
       " 'génome',\n",
       " 'structure',\n",
       " 'protéine',\n",
       " 'organisme',\n",
       " 'réponse',\n",
       " 'thérapeutique',\n",
       " 'million_dollar',\n",
       " 'intelligence_artificiel']"
      ]
     },
     "execution_count": 295,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens_data[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Phrases "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Adding bigrams\n",
    "#bigrams_list = []\n",
    "bigram = Phrases(tokens_data, min_count=50) #gensim\n",
    "for idx in range(len(tokens_data)):\n",
    "    for token in bigram[tokens_data[idx]]:\n",
    "        if '_' in token:\n",
    "            # Token is a bigram, add to document.\n",
    "            tokens_data[idx].append(token)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'compagnie_aérien'"
      ]
     },
     "execution_count": 272,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#bigrams_list[1] testing whether it works "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'nouveau'"
      ]
     },
     "execution_count": 274,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens_data[1][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6193"
      ]
     },
     "execution_count": 275,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokens_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary_data= Dictionary(tokens_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6834"
      ]
     },
     "execution_count": 288,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dictionary_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary_data.filter_extremes(no_below=10, no_above=0.8, keep_n= 100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary_tfidf = Dictionary(tokens_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_data = [dictionary_data.doc2bow(doc) for doc in tokens_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary_tfidf.filter_extremes(no_below=10, no_above=0.8, keep_n= 100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "#Tf-Idf for word frequency filter \n",
    "\n",
    "from gensim.models.tfidfmodel import TfidfModel\n",
    "tfidf = TfidfModel(test_corpus)\n",
    "tfidf = TfidfModel(test_corpus, id2word = test_dictionary)\n",
    "low_value = 0.2\n",
    "low_value_words = []\n",
    "for bow in test_corpus:\n",
    "    low_value_words += [id for id, value in tfidf[bow] if value < low_value]\n",
    "test_dictionary.filter_tokens(bad_ids=low_value_words) \n",
    "new_corpus = [test_dictionary.doc2bow(doc) for doc in test_tokens] \n",
    "\"\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_model = LdaMulticore(corpus=corpus_1000, id2word=dictionary_1000, iterations=50, num_topics=10, workers = 4, passes=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_model2 = LdaMulticore(corpus=corpus_kn, id2word=dictionary_kn, iterations=50, num_topics=10, workers = 4, passes=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_model_ten = LdaMulticore(corpus=corpus_ten, id2word=dictionary_ten, iterations=50, num_topics=5, workers = 4, passes=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_model_ten_2 = LdaMulticore(corpus=corpus_ten, id2word=dictionary_ten, iterations=50, num_topics=5, workers = 4, passes=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_model_data = LdaMulticore(corpus=corpus_data, id2word=dictionary_data, iterations=50, num_topics=4, workers = 4, passes=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_model_data_5 = LdaMulticore(corpus=corpus_data, id2word=dictionary_data, iterations=50, num_topics=5, workers = 4, passes=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pyLDAvis.gensim\n",
    "\n",
    "LDAvis = pyLDAvis.gensim.prepare(lda_model_data, corpus_data, dictionary_data)\n",
    "path = os.path.join('.results')\n",
    "\n",
    "with open(path, 'wb') as f:\n",
    "    pickle.dump(LDAvis,f)\n",
    "\n",
    "with open(path, 'rb') as f:\n",
    "    LDAvis = pickle.load(f)\n",
    "\n",
    "pyLDAvis.save_html(LDAvis, './results' + '_lda_data' + '.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pyLDAvis.gensim\n",
    "\n",
    "LDAvis = pyLDAvis.gensim.prepare(lda_model_data_5, corpus_data, dictionary_data)\n",
    "path = os.path.join('.results')\n",
    "\n",
    "with open(path, 'wb') as f:\n",
    "    pickle.dump(LDAvis,f)\n",
    "\n",
    "with open(path, 'rb') as f:\n",
    "    LDAvis = pickle.load(f)\n",
    "\n",
    "pyLDAvis.save_html(LDAvis, './results' + '_lda_data_5' + '.html')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11.3 ('nlp_env': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9bd3ed14e90b49bd08368fcba8ccdf7178aebb376bc97a25599cb1e04c3b1d0e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
